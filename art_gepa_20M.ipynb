{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead79485",
   "metadata": {
    "hide_input": true,
    "skipped": true
   },
   "source": [
    "## Article: How I unlocked tremendous value by Automating Prompt Engineering at Enterprise Scale\n",
    "\n",
    "Section 1: The Problem: \"Manual Prompt Engineering is non-deterministic and doesn't scale. I needed a system.\"\n",
    "additional context: I wanted to unlock value from interaction data with the company such as calls & chats. I had tried finetuning, manual prompt engineering for years.\n",
    "\n",
    "Section 2: The \"internal champion â†’ team adoption\"\n",
    "What convinced you first (early results? a specific win?)\n",
    "How you got buy-in from others (demo? pilot project?)\n",
    "\n",
    "Section 2: The Architecture\n",
    "Diagram your flow: DSPy -> Genetic Mutation -> Evaluation Harness -> Pareto Selection.\n",
    "Discuss the constraints: How we did a POC, scaled across teams for v1 of prompts\n",
    "\n",
    "Section 3: The Evaluation Engine\n",
    "built a system targetting feedback for failing  cases\n",
    "\n",
    "Section 4: The Impact -> manual prompt engineering to automated savings\n",
    "\n",
    "Section 5: What we learned and how we would do it going forward.\n",
    "clear target and dog fooded dataset(v1) -> run gepa -> targetted feedback for failing cases -> run gepa -> stop when we are fine with metrics -> deploy\n",
    "post deployment -> look for failing cases -> add to dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e025be",
   "metadata": {},
   "source": [
    "## Article: How I Unlocked Tremendous Value by Automating Prompt Engineering at Enterprise Scale\n",
    "\n",
    "**Section 1: The Problem**\n",
    "* POC with prompts look interesting -> now we need it work at scale.\n",
    "* Manual prompt engineering is non-deterministic and doesn't scale. I needed a system to unlock value from unstructured customer interaction data. Years of fine-tuning and manual prompt iteration weren't cutting it.\n",
    "* I was so desperate for a solution as LLMs gave good feedbacks, why cant it convert it into good prompts\n",
    "* I was reading a lot before i stumbled upon DSPy and prompt optimizers. It kind of clicked and when this new optimizer GEPA came in. I wanted to test it.\n",
    "\n",
    "**Section 2: From Pilot to Adoption**\n",
    "* I created a dummy dataset resembling a generic problem in interaction  to see if its moving in right direction.\n",
    "* I expected weeks of iteration but got results in one run.\n",
    "* What convinced me: early results on a pilot use case\n",
    "* Initial quality of prompts impressed me while it was in its loop.\n",
    "* Ran for 10 Hours $2 and 200+ â†’ 9 survivors\n",
    "* How I got buy-in: demo showing measurable improvement over baseline\n",
    "\n",
    "**Section 3: The Architecture**\n",
    "High level flow Diagram of how GEPA works: DSPy â†’ Genetic Mutation â†’ Evaluation Harness â†’ Pareto Selection\n",
    "refer to https://risheekkumar.in/posts/gepa-deepdive/gepa_final_article.html for deepdive\n",
    "- I setup this experiment\n",
    "Task: Analyzing sales call transcripts to classify agent behaviors into categories (like \"introduction_rapport_building\", \"objection_handling\") and predict call outcome (good/bad)\n",
    "Dataset: 27 labeled call transcripts split into train/val/test sets\n",
    "Base model: A CallAnalysisAgent using dspy.ChainOfThought that reads transcripts and outputs categories + final result\n",
    "Optimization: GEPA iteratively rewrites the prompt instructions, testing variants on the validation set. It maintains a \"Pareto front\" of candidate prompts that excel on different examples\n",
    "Results:72% -> 81% accuracy\n",
    "* Started with a focused POC on a single use case, everyone adopted seeing how fast and better it is.\n",
    "\n",
    "**Section 4: Using error analysis on top of GEPA**\n",
    "* Results were promising (81% accuracy) which i used internally and it worked everywhere where it was implemented properly\n",
    "* But i faced the next challenge on how it take to further heights. Because the cases which it failed were not that difficult, llm could identify if given an hint.(that was my hunch)\n",
    "* Problem: how to guide the automation to the type of prompt to make the cases it was failing.\n",
    "| Input (truncated) | Actual | Pred | targeted Feedback |\n",
    "|---|---|---|---|\n",
    "| Tyler calling from Amex... \"sounds good, I'll send that link...\" | bad | good | The customer showed hesitation (\"I'm really not sure...\") and the agent rushed to close without addressing concerns. A \"bad\" call lacks proper objection handling before closing. |\n",
    "| Mark from Amex calling about credit solutions... | bad (intro_rapport=false) | bad (intro_rapport=true) | The agent said \"Hi, this is Mark from Amex\" without warmth, time acknowledgment, or rapport-building. A bare introduction doesn't qualify as introduction_rapport_building. |\n",
    "| John from American Express... | bad (intro_rapport=false) | bad (intro_rapport=true) | Similarâ€”the agent jumped straight into the pitch. Greeting alone isn't rapport-building; look for courtesy, time check, or warmth signals. |\n",
    "\n",
    "The pattern: the model over-detects `introduction_rapport_building` (any greeting = rapport) and sometimes misses when a call is actually \"bad\" despite having next steps.\n",
    "* Built a system using excel that generates targeted feedback for failing cases\n",
    "* Results improved to 81% -> 90%\n",
    "\n",
    "**Section 5: The Impact**\n",
    "* 72% -> 81% -> 90% was right in line and process was repeatable. All i need to do is error analysis and give proper feedback.\n",
    "* Shifted from manual prompt iteration (days/weeks) to automated optimization (hours). Significant reduction in prompt engineering effort per use case.\n",
    "\n",
    "**Section 6: Lessons Learned & Recommended Workflow**\n",
    "when not to use GEPA: when y variable is unclear, you are not able to do it clearly as a human.\n",
    "1. Start with a clear target metric and a dogfooded dataset (v1)\n",
    "2. Run GEPA â†’ review failing cases â†’ add targeted feedback\n",
    "3. Run GEPA again â†’ stop when metrics are acceptable â†’ deploy\n",
    "4. Post-deployment: monitor for failures â†’ add to dataset â†’ iterate\n",
    "\n",
    "**Section 7: Production considerations**\n",
    "1. dspy integration with mlflow is one straight forward for monitoring & versioning - linking article.\n",
    "2. when to add the failure case to the evaluation dataset is a business call\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373fbe1",
   "metadata": {
    "time_run": "2025-12-30T09:12:38.664103+00:00"
   },
   "outputs": [],
   "source": [
    "from dialoghelper import *\n",
    "tool_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db2018",
   "metadata": {},
   "source": [
    "Tools available from dialoghelper: &`[curr_dialog, msg_idx, add_html, find_msg_id, find_msgs, read_msg, del_msg, add_msg, update_msg, msg_insert_line, msg_str_replace, msg_strs_replace, msg_replace_lines]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06a1c5",
   "metadata": {},
   "source": [
    "### this article is for engineering leaders or practitioners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a0a30",
   "metadata": {},
   "source": [
    "## Article: How I Unlocked Tremendous Value by Automating Prompt Engineering at Enterprise Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c39c1",
   "metadata": {},
   "source": [
    "## **Section 1: The Problem**\n",
    "\n",
    "I'd built plenty of successful POCs with LLM promptsâ€”they always looked impressive in demos. But when it came time to deploy at scale, everything fell apart. Manual prompt engineering is fundamentally non-deterministic: what works today might fail tomorrow, and there's no systematic way to improve it.\n",
    "\n",
    "My challenge was unlocking value from years of unstructured customer interaction data. I'd spent three weeks fine-tuning a single prompt by hand, iterating through variations, hoping to stumble on something that worked consistently. It wasn't cutting it.\n",
    "\n",
    "**Then it hit me:** LLMs are remarkably good at *giving feedback*. They can look at their own outputs and tell you exactly what went wrong. So why couldn't they convert that feedback into better prompts automatically? Surely something existed to solve this.\n",
    "\n",
    "I searched for tools that could close this loop automatically[^1]. That's when I stumbled upon [DSPy](https://thedataquarry.com/blog/learning-dspy-1-the-power-of-good-abstractions/) and the concept of prompt optimizersâ€”systems that treat prompt engineering as an optimization problem rather than an art. It clicked immediately. When [GEPA](https://dspy.ai/tutorials/gepa_aime/) was released, I knew I had to test it.\n",
    "\n",
    "Think of it like compilation: you write high-level code (your task definition), and the compiler transforms it into optimized machine instructions (a battle-tested prompt). You don't hand-tune assemblyâ€”so why hand-tune prompts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c93745d",
   "metadata": {},
   "source": [
    "## **Section 2: The Pilot**\n",
    "\n",
    "I needed a simple test to see if GEPA could work for my use case. So I created a synthetic dataset of 27 sales call transcripts that represented a real challenge we face: **detecting presence of required behaviors and predicting call quality (good/bad)**. The transcripts were hand-labeled across 7 behavior categories `(introduction, needs, value proposition, objection handling, benefit reinforcement, risk reduction, and closing)`. Small enough to iterate fast, realistic enough to validate the approachâ€”and representative of a problem I'd hit repeatedly: intent extraction and call evaluation look easy for a few cases, but precision and recall tank at scale.\n",
    "\n",
    "I expected weeks of iteration. Instead, I got meaningful results in a single run.\n",
    "Usually a show piece like this would be carefully selected sample to show the power of the approach. Here this is literally first attempt, that in itself tells the power of the approach.\n",
    "\n",
    "### Results\n",
    "\n",
    "| Approach | Cost | Time | Accuracy |\n",
    "|----------|------|------|----------|\n",
    "| Manual prompt engineering | $100-1000 (engineer time) | Days to weeks | 72% |\n",
    "| **GEPA** | ~$2 | 10 hours | 81% |\n",
    "| GEPA with error analysis | ~$0.5 | 3 hours | 90% |\n",
    "\n",
    "The optimizer ran for about 10 hours, cost roughly $2, and explored over 200 prompt variants. Through genetic mutation and Pareto selection, it whittled those down to 9 \"survivors\"â€”prompts that excelled at different subsets of the problem. The best performer jumped from 72% to 81% accuracy, a lift I hadn't achieved in months of manual tuning.\n",
    "\n",
    "What really convinced me wasn't just the final numberâ€”it was watching the intermediate prompts evolve. I could see the optimizer discovering nuances I'd never thought to include: explicit definitions for each category, step-by-step rules for edge cases, domain-specific guidance about soft pulls versus hard pulls. The quality of the reasoning it produced while iterating was genuinely impressive.\n",
    "\n",
    "Hopefully I have convinced you that this method is powerful, lets see how i did it and you can follow similar steps for yours as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe17d50",
   "metadata": {
    "collapsed": true,
    "hide_input": true,
    "skipped": true,
    "time_run": "2025-12-30T09:12:38.727344+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"border: 2px solid #f4f4f4; padding: 15px; border-radius: 8px; background: #f2f2f2ff;\">\n",
       "  <h3 style=\"color: #1d1d1dff;\">Sample Dataset</h3>\n",
       "  <table style=\"width: 100%; border-collapse: collapse; font-size: 13px;\">\n",
       "    <thead>\n",
       "      <tr style=\"background-color: #27ae60; color: white;\">\n",
       "        <th style=\"padding: 10px; text-align: left; border-radius: 4px 0 0 0;\">transcript (Input)</th>\n",
       "        <th style=\"padding: 10px; text-align: left;\">Categories present (Output)</th>\n",
       "        <th style=\"padding: 10px; text-align: left; border-radius: 0 4px 0 0;\">Call Quality (Output)</th>\n",
       "      </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "      <tr style=\"background: white;\">\n",
       "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">agent: Hi, good afternoon â€” this is Maya calling from American Express...</td>\n",
       "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">intro_rapport, needs_assessment, objection_handling, benefit_reinforcement, risk_reduction, call_to_action</td>\n",
       "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd; color: #27ae60; font-weight: bold;\">good</td>\n",
       "      </tr>\n",
       "      <tr style=\"background: #f9f9f9;\">\n",
       "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">agent: Hi! Good morningâ€”this is Tyler calling from Amex...</td>\n",
       "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">intro_rapport, needs_assessment, value_prop, objection_handling</td>\n",
       "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd; color: #c0392b; font-weight: bold;\">bad</td>\n",
       "      </tr>\n",
       "      <tr style=\"background: white;\">\n",
       "        <td style=\"padding: 10px;\">agent: Hi, this is Mark from Amex, calling about our credit solutions...</td>\n",
       "        <td style=\"padding: 10px;\">value_prop, call_to_action</td>\n",
       "        <td style=\"padding: 10px; color: #c0392b; font-weight: bold;\">bad</td>\n",
       "      </tr>\n",
       "    </tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<div style=\"border: 2px solid #f4f4f4; padding: 15px; border-radius: 8px; background: #f2f2f2ff;\">\n",
    "  <h3 style=\"color: #1d1d1dff;\">Sample Dataset</h3>\n",
    "  <table style=\"width: 100%; border-collapse: collapse; font-size: 13px;\">\n",
    "    <thead>\n",
    "      <tr style=\"background-color: #27ae60; color: white;\">\n",
    "        <th style=\"padding: 10px; text-align: left; border-radius: 4px 0 0 0;\">transcript (Input)</th>\n",
    "        <th style=\"padding: 10px; text-align: left;\">Categories present (Output)</th>\n",
    "        <th style=\"padding: 10px; text-align: left; border-radius: 0 4px 0 0;\">Call Quality (Output)</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr style=\"background: white;\">\n",
    "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">agent: Hi, good afternoon â€” this is Maya calling from American Express...</td>\n",
    "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">intro_rapport, needs_assessment, objection_handling, benefit_reinforcement, risk_reduction, call_to_action</td>\n",
    "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd; color: #27ae60; font-weight: bold;\">good</td>\n",
    "      </tr>\n",
    "      <tr style=\"background: #f9f9f9;\">\n",
    "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">agent: Hi! Good morningâ€”this is Tyler calling from Amex...</td>\n",
    "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">intro_rapport, needs_assessment, value_prop, objection_handling</td>\n",
    "        <td style=\"padding: 10px; border-bottom: 1px solid #ddd; color: #c0392b; font-weight: bold;\">bad</td>\n",
    "      </tr>\n",
    "      <tr style=\"background: white;\">\n",
    "        <td style=\"padding: 10px;\">agent: Hi, this is Mark from Amex, calling about our credit solutions...</td>\n",
    "        <td style=\"padding: 10px;\">value_prop, call_to_action</td>\n",
    "        <td style=\"padding: 10px; color: #c0392b; font-weight: bold;\">bad</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf9bf5",
   "metadata": {
    "collapsed": true,
    "hide_input": true,
    "time_run": "2025-12-31T05:37:40.329306+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:flex; gap:20px; font-family:system-ui,-apple-system,sans-serif;\">\n",
       "  <div style=\"flex:1; background:#f8f9fa; border-radius:12px; padding:20px; border:1px solid #e0e0e0;\">\n",
       "    <h3 style=\"margin:0 0 12px 0; color:#1a73e8; font-size:14px; text-transform:uppercase; letter-spacing:1px;\">ðŸ“ž Input: Call Transcript</h3>\n",
       "    <div style=\"background:white; padding:16px; border-radius:8px; font-size:13px; line-height:1.6; max-height:300px; overflow-y:auto; white-space:pre-wrap; color:#333;\">agent: Hi, good afternoon â€” this is Maya calling from American Express. Am I speaking with Jordan Lee?\n",
       "\n",
       "customer: Yes, this is Jordan.\n",
       "\n",
       "agent: Great, Jordan. How are you doing today?\n",
       "\n",
       "customer: I'm good, thanks. Busy afternoon, but I have a few minutes.\n",
       "\n",
       "agent: I appreciate you taking the time...</div>\n",
       "  </div>\n",
       "  <div style=\"flex:1; background:#f0f7f0; border-radius:12px; padding:20px; border:1px solid #c8e6c9;\">\n",
       "    <h3 style=\"margin:0 0 12px 0; color:#2e7d32; font-size:14px; text-transform:uppercase; letter-spacing:1px;\">ðŸ“Š Output: Analysis</h3>\n",
       "    <div style=\"background:white; padding:16px; border-radius:8px; margin-bottom:12px;\">\n",
       "      <div style=\"font-size:12px; color:#666; margin-bottom:4px;\">Call Quality</div>\n",
       "      <div style=\"font-size:24px; font-weight:600; color:#2e7d32;\">âœ“ Good</div>\n",
       "    </div>\n",
       "    <div style=\"background:white; padding:16px; border-radius:8px;\">\n",
       "      <div style=\"font-size:12px; color:#666; margin-bottom:8px;\">Detected Categories</div>\n",
       "      <div style=\"display:flex; flex-wrap:wrap; gap:6px;\">\n",
       "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Introduction/Rapport âœ“</span>\n",
       "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Need Assessment âœ“</span>\n",
       "        <span style=\"background:#ffebee; color:#c62828; padding:4px 10px; border-radius:16px; font-size:12px;\">Value Proposition âœ—</span>\n",
       "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Objection Handling âœ“</span>\n",
       "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Benefit Reinforcement âœ“</span>\n",
       "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Risk Reduction âœ“</span>\n",
       "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Call to Action âœ“</span>\n",
       "      </div>\n",
       "    </div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<div style=\"display:flex; gap:20px; font-family:system-ui,-apple-system,sans-serif;\">\n",
    "  <div style=\"flex:1; background:#f8f9fa; border-radius:12px; padding:20px; border:1px solid #e0e0e0;\">\n",
    "    <h3 style=\"margin:0 0 12px 0; color:#1a73e8; font-size:14px; text-transform:uppercase; letter-spacing:1px;\">ðŸ“ž Input: Call Transcript</h3>\n",
    "    <div style=\"background:white; padding:16px; border-radius:8px; font-size:13px; line-height:1.6; max-height:300px; overflow-y:auto; white-space:pre-wrap; color:#333;\">agent: Hi, good afternoon â€” this is Maya calling from American Express. Am I speaking with Jordan Lee?\n",
    "\n",
    "customer: Yes, this is Jordan.\n",
    "\n",
    "agent: Great, Jordan. How are you doing today?\n",
    "\n",
    "customer: I'm good, thanks. Busy afternoon, but I have a few minutes.\n",
    "\n",
    "agent: I appreciate you taking the time...</div>\n",
    "  </div>\n",
    "  <div style=\"flex:1; background:#f0f7f0; border-radius:12px; padding:20px; border:1px solid #c8e6c9;\">\n",
    "    <h3 style=\"margin:0 0 12px 0; color:#2e7d32; font-size:14px; text-transform:uppercase; letter-spacing:1px;\">ðŸ“Š Output: Analysis</h3>\n",
    "    <div style=\"background:white; padding:16px; border-radius:8px; margin-bottom:12px;\">\n",
    "      <div style=\"font-size:12px; color:#666; margin-bottom:4px;\">Call Quality</div>\n",
    "      <div style=\"font-size:24px; font-weight:600; color:#2e7d32;\">âœ“ Good</div>\n",
    "    </div>\n",
    "    <div style=\"background:white; padding:16px; border-radius:8px;\">\n",
    "      <div style=\"font-size:12px; color:#666; margin-bottom:8px;\">Detected Categories</div>\n",
    "      <div style=\"display:flex; flex-wrap:wrap; gap:6px;\">\n",
    "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Introduction/Rapport âœ“</span>\n",
    "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Need Assessment âœ“</span>\n",
    "        <span style=\"background:#ffebee; color:#c62828; padding:4px 10px; border-radius:16px; font-size:12px;\">Value Proposition âœ—</span>\n",
    "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Objection Handling âœ“</span>\n",
    "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Benefit Reinforcement âœ“</span>\n",
    "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Risk Reduction âœ“</span>\n",
    "        <span style=\"background:#e8f5e9; color:#2e7d32; padding:4px 10px; border-radius:16px; font-size:12px;\">Call to Action âœ“</span>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077f190",
   "metadata": {
    "hide_input": true,
    "skipped": true
   },
   "source": [
    "**Section 3: The Architecture**\n",
    "\n",
    "Let me walk you through how I actually set this up. At its core, GEPA follows a simple loop: generate prompt variants â†’ evaluate them â†’ select the best survivors â†’ repeat. But the magic is in the details.\n",
    "\n",
    "**The Setup**\n",
    "\n",
    "I used DSPy's `ChainOfThought` module to define my task: given a call transcript, output (1) which behavioral categories the agent demonstrated, and (2) whether the call outcome was good or bad. My initial prompt was embarrassingly simpleâ€”just two lines describing what I wanted. The model knew *what* to do but had no guidance on *how* to do it well.\n",
    "\n",
    "**How GEPA Works**\n",
    "\n",
    "The optimizer runs in iterations. Each cycle:\n",
    "1. **Genetic Mutation**: The LLM looks at failing cases and their feedback, then proposes improved instructions. It's not random mutationâ€”it's *reflective* mutation, guided by what went wrong.\n",
    "2. **Evaluation Harness**: Each candidate prompt runs against the validation set and gets scored.\n",
    "3. **Pareto Selection**: Here's the clever bitâ€”GEPA doesn't just keep the single best prompt. It maintains a \"Pareto front\" of diverse specialists. One prompt might excel at detecting objection handling; another might be better at call outcome prediction. This diversity prevents the optimizer from over-fitting to one pattern and forgetting others.\n",
    "\n",
    "**What I Observed**\n",
    "\n",
    "My 2-line prompt evolved into a ~1,500 word instruction set. The optimizer discovered things I'd never explicitly taught it: precise definitions for each category, rules for ambiguous cases (\"a bare greeting isn't rapport-buildingâ€”look for warmth and time acknowledgment\"), and domain-specific guidance about soft pulls and secure application links.\n",
    "\n",
    "The result: 72% â†’ 81% accuracy. More importantly, the process was repeatable. I wasn't guessing anymoreâ€”I had a system.\n",
    "\n",
    "For a deeper technical dive, I wrote up the internals here: [GEPA Deepdive](https://risheekkumar.in/posts/gepa-deepdive/gepa_final_article.html)</cellsource></message>\n",
    "</invoke>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d219929",
   "metadata": {
    "hide_input": true,
    "skipped": true
   },
   "outputs": [],
   "source": [
    "final_prompt = \"\"\"New Instructions for Analyzing Banking/Card Transaction Call Transcripts\n",
    "\n",
    "Overview\n",
    "You are an analysis assistant whose job is to evaluate sales/transactâ€‘ion-focused call transcripts in the banking/credit-card domain. For each transcript, produce a compact, structured analysis with two main objectives:\n",
    "  (a) identify the agent behavior categories demonstrated (from the seven pillars below), and\n",
    "  (b) judge the likely business outcome of the call (conversion, retention, or mixed).\n",
    "\n",
    "Inputs you will receive\n",
    "- A complete transcript of a single call between an agent and a customer. Transcripts may include labels such as â€œagent:â€ and â€œcustomer:â€ and may cover topics like card offers, fees, rewards, security, and next steps.\n",
    "\n",
    "What you must produce (three sections exactly)\n",
    "1) reasoning\n",
    "   - Provide a concise, bullets-style justification for every pillar category you detected in the transcript.\n",
    "   - Include short quotes or paraphrases from the transcript to illustrate why the category applies. Do not introduce facts or assumptions beyond what is in the transcript.\n",
    "   - If you detect a strength/weakness signal about the outcome, include a brief, one- to two-sentence note here describing how strong the signal is and what would push it toward conversion or toward retention.\n",
    "   - This section may contain a small, optional note about outcome strength, but must not introduce information outside the transcript.\n",
    "\n",
    "2) categories\n",
    "   - Output a Python-like list of the detected pillar categories in the exact order they first appeared in the transcript.\n",
    "   - Example format: ['introduction_rapport_building', 'need_assessment_qualification', ...]\n",
    "\n",
    "3) final_result\n",
    "   - A single word indicating the likely business outcome:\n",
    "     - conversion â€” the call is progressing toward an immediate or near-term application/upgrade/activation.\n",
    "     - retention â€” the call focuses on keeping an existing customer, avoiding churn, or upselling within retention without an immediate conversion.\n",
    "     - mixed â€” signals of both retention and conversion, or the outcome is uncertain and depends on future steps.\n",
    "   - Do not add any qualifiers in this field; use exactly one of the three keywords above.\n",
    "\n",
    "Optional but encouraged: assess the strength of the outcome\n",
    "- If you include it (recommendation), place this assessment only in reasoning as the optional strength_of_outcome note. Keep it concise (one or two sentences). It should address:\n",
    "  - How strong is the conversion/retention signal?\n",
    "  - What would most likely push the outcome toward conversion, or toward retention?\n",
    "\n",
    "Pillar definitions (seven bank/card-specific categories)\n",
    "- introduction_rapport_building\n",
    "  - Includes opening greetings, courtesy, acknowledgment of time, and attempts to establish rapport.\n",
    "  - Examples: greetings, confirming time, polite introductions, small talk about fit or time constraints.\n",
    "- need_assessment_qualification\n",
    "  - Involves asking about customer needs, usage, spend patterns, eligibility checks, and whether the product fits (e.g., business vs personal, employee cards, annual fees, soft vs hard pulls).\n",
    "- value_proposition_feature_mapping\n",
    "  - Linking card features to tangible, customer-relevant benefits (rewards, protections, credits) and showing how those features align with stated needs.\n",
    "- objection_handling\n",
    "  - Addressing concerns about price, complexity, trust, enrollment, or process obstacles. Includes acknowledging concerns and offering clarifications or mitigations.\n",
    "- benefit_reinforcement\n",
    "  - Reiterating concrete benefits and value after objections or hesitations, often tying back to the customerâ€™s stated needs.\n",
    "- risk_reduction_trust_building\n",
    "  - Providing security assurances, privacy protections, non-hard-pull options, guarantees, terms clarity, or brand trust signals.\n",
    "- call_to_action_closing\n",
    "  - Concrete next steps or commitments: soft checks, secure links, email/mail options, scheduling follow-ups, or instructions to apply/get more information.\n",
    "\n",
    "How to apply the rules\n",
    "- For every transcript, read from start to finish. Mark each pillar as soon as its criteria are clearly demonstrated.\n",
    "- If a single utterance clearly satisfies more than one pillar, count it under all applicable pillars.\n",
    "- If a pillar is not clearly demonstrated anywhere in the transcript, do not include it in the categories list.\n",
    "- Record the detected pillars in the exact order of their first appearance in the transcript.\n",
    "- The final_result should reflect the overall trajectory of the call as described above.\n",
    "\n",
    "Output constraints and format\n",
    "- Do not introduce any facts not present in the transcript.\n",
    "- Do not insert subjective opinions beyond what is grounded in the transcript.\n",
    "- Use the exact section headings and formatting:\n",
    "  reasoning\n",
    "  categories\n",
    "  final_result\n",
    "- Do not include extraneous content beyond the three sections above.\n",
    "\n",
    "Domain-specific considerations\n",
    "- You may encounter references to soft pulls vs hard pulls, online applications, secure links, email follow-ups, or scheduled follow-ups. Treat these as legitimate â€œcall_to_action_closingâ€ or â€œrisk_reduction_trust_buildingâ€ elements as appropriate.\n",
    "- When quoting or paraphrasing, keep quotes brief and focused on the reason for the pillar.\n",
    "- If PII appears in the transcript (e.g., partial SSN or addresses), quote minimally and do not reveal full sensitive data in your justification. You may paraphrase or reference the presence of sensitive data without reproducing it.\n",
    "\n",
    "Example behavior (not to reproduce here)\n",
    "- A transcript with strong, explicit next steps to apply or pre-qualify is more conversion-oriented; a transcript focusing solely on questions and reassurance without a clear next step is more retention-oriented or mixed.\n",
    "\n",
    "End result\n",
    "- Return exactly three sections for every transcript analyzed, with the content governed by the rules above. This format enables consistent, comparable, and transparent analysis across transcripts.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e624ec",
   "metadata": {
    "skipped": true
   },
   "source": [
    "## **Section 3: The Architecture**\n",
    "\n",
    "We are going to use DSPy for using GEPA.\n",
    "\n",
    "> *If you're new to DSPy: it's a framework that treats prompts as code you can optimize programmatically, rather than strings you tweak by hand. For a deeper technical introduction, see [The Data Quarry's guide](https://thedataquarry.com/blog/learning-dspy-3-working-with-optimizers/).*\n",
    "\n",
    "### Prerequisites for Optimization\n",
    "\n",
    "Before running any optimizer, you need three things:\n",
    "\n",
    "| Component | What it does | Why it matters |\n",
    "|-----------|--------------|----------------|\n",
    "| **DSPy Signature (The Prompt)** | Your baseline module defining the task | The \"thing\" being optimized |\n",
    "| **Metric Function** | Returns score and textual feedback | Tells optimizer what \"good\" looks like |\n",
    "| **Dataset** | Labeled examples (train/val/test) | Ground truth for evaluation |\n",
    "\n",
    "The key insight: **optimizers need textual feedback, not just scores.** If you only return a number, the optimizer is flying blind. If you return *why* something failed, it can propose smarter mutations.\n",
    "\n",
    "### The DSPy Setup\n",
    "\n",
    "**Code Walkthrough**\n",
    "\n",
    "I used DSPy's `ChainOfThought` module to define my task: given a call transcript, output (1) which behavioral categories the agent demonstrated, and (2) whether the call outcome was good or bad. My initial prompt was embarrassingly simpleâ€”just two lines describing what I wanted:\n",
    "\n",
    "```python\n",
    "class CallAnalysis(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Read the provided call transcript and analyze it comprehensively.\n",
    "    Determine both: (1) which categories the agent displayed, and \n",
    "    (2) whether the call will lead to conversion or customer retention.\n",
    "    \"\"\"\n",
    "    message: str = dspy.InputField()\n",
    "    categories: List[Literal[\"introduction_rapport_building\", \"need_assessment_qualification\", \n",
    "                             \"value_proposition_feature_mapping\", \"objection_handling\", \n",
    "                             \"benefit_reinforcement\", \"risk_reduction_trust_building\", \n",
    "                             \"call_to_action_closing\"]] = dspy.OutputField()\n",
    "    final_result: Literal['good', 'bad'] = dspy.OutputField()\n",
    "\n",
    "program = dspy.ChainOfThought(CallAnalysis)\n",
    "```\n",
    "\n",
    "The model knew *what* to do but had no guidance on *how* to do it well.\n",
    "\n",
    "**Metrics for success**\n",
    "\n",
    "```python\n",
    "def call_qual_metric(gold, pred):\n",
    "    return 1.0 if gold == pred else 0.0\n",
    "\n",
    "def category_qual_metric(gold, pred):\n",
    "    \"\"\"Compute score for categories using set operations.\"\"\"\n",
    "    pred_set = set(pred)\n",
    "    gold_true = {k for k, v in gold.items() if v}\n",
    "    gold_false = {k for k, v in gold.items() if not v}\n",
    "    \n",
    "    correct = len(gold_true & pred_set) + len(gold_false - pred_set)\n",
    "    return correct / len(gold)\n",
    "\n",
    "def comb_metric(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"Overall metric combining both scores.\"\"\"\n",
    "    call_qual = call_qual_metric(gold.final_result, pred.final_result)\n",
    "    category_qual = category_qual_metric(gold.categories, pred.categories)\n",
    "    return (call_qual + category_qual) / 2\n",
    "```\n",
    "\n",
    "### Adding in GEPA\n",
    "\n",
    "This is the key enabler for GEPA's reflective mutationâ€”returning *textual feedback*, not just a score:\n",
    "\n",
    "![A simplified GEPA flow diagram](gepa_flow_simplified.png)\n",
    "\n",
    "The insight: when GEPA sees a failure, it doesn't just know \"this was wrong\"â€”it knows *why* and can propose smarter mutations.\n",
    "\n",
    "\n",
    "```python\n",
    "def call_qual_feedback(gold, pred):\n",
    "    \"\"\" Generate feedback for final result module. \"\"\"\n",
    "    if gold == pred:\n",
    "        fb = f\"You correctly classified the sales call as `{gold}`. This sales call is indeed `{gold}`.\"\n",
    "    else:\n",
    "        fb = f\"You incorrectly classified the sales call as `{pred}`. The correct sales call is `{gold}`. Think about how you could have reasoned to get the correct sales call label.\"\n",
    "    return fb\n",
    "\n",
    "def category_qual_feedback(gold, pred):\n",
    "    \"\"\"Generate feedback using set operations.\"\"\"\n",
    "    pred_set = set(pred)\n",
    "    gold_true = {k for k, v in gold.items() if v}\n",
    "    gold_false = {k for k, v in gold.items() if not v}\n",
    "    \n",
    "    correctly_included = gold_true & pred_set\n",
    "    incorrectly_included = gold_false & pred_set\n",
    "    incorrectly_excluded = gold_true - pred_set\n",
    "    correctly_excluded = gold_false - pred_set\n",
    "    \n",
    "    score = (len(correctly_included) + len(correctly_excluded)) / len(gold)\n",
    "    \n",
    "    if score == 1.0:\n",
    "        return f\"Perfect. Correctly identified: `{correctly_included}`.\", score\n",
    "    \n",
    "    fb = f\"Correctly identified: `{correctly_included}`.\\n\"\n",
    "    if incorrectly_included:\n",
    "        fb += f\"False positives: `{incorrectly_included}`.\\n\"\n",
    "    if incorrectly_excluded:\n",
    "        fb += f\"Missed: `{incorrectly_excluded}`.\\n\"\n",
    "    return fb\n",
    "\n",
    "def comb_metric_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    Computes a score and provides feedback for the call analysis prediction.\n",
    "    Returns total score if pred_name is None, otherwise returns dspy.Prediction with score and feedback.\n",
    "    \"\"\"\n",
    "    # Compute feedback and scores\n",
    "    cal_fb = call_qual_feedback(gold.final_result, pred.final_result)\n",
    "    cat_fb = category_qual_feedback(gold.categories, pred.categories)\n",
    "    fb = cal_fb + '\\n' + cat_fb\n",
    "    score = comb_metric(gold, pred)\n",
    "    return dspy.Prediction(score=score, feedback=fb)\n",
    "```\n",
    "\n",
    "### How GEPA Works Under the Hood\n",
    "\n",
    "Before showing the code, let's understand what GEPA actually does:\n",
    "\n",
    "1. **Reflective Mutation** â€” Unlike random genetic mutation, GEPA's LLM *reads the failure feedback* and proposes targeted improvements. It's not guessingâ€”it's reasoning about what went wrong.\n",
    "\n",
    "2. **Pareto Selection** â€” Instead of keeping only the single best prompt, GEPA maintains a \"frontier\" of diverse specialists. One prompt might excel at detecting objection handling; another at predicting call outcomes. This prevents catastrophic forgetting.\n",
    "\n",
    "3. **Text-as-Feedback** â€” Traditional RL uses scalar rewards. GEPA exploits rich textual feedback (\"You incorrectly marked this as rapport-building because...\") to guide mutations more precisely.\n",
    "\n",
    "### Running GEPA\n",
    "\n",
    "With prerequisites in place, the optimizer setup is straightforward:\n",
    "\n",
    "```python\n",
    "from dspy import GEPA\n",
    "\n",
    "optimizer = GEPA(\n",
    "    metric=metric_with_feedback,  # Returns score + textual feedback for failures\n",
    "    auto=\"light\",                 # Budget setting (use \"heavy\" for production)\n",
    ")\n",
    "\n",
    "optimized_program = optimizer.compile(\n",
    "    program,\n",
    "    trainset=train_set,\n",
    "    valset=val_set,\n",
    ")\n",
    "```\n",
    "\n",
    "### What I Observed\n",
    "\n",
    "My 2-line prompt evolved into a ~1,500 word instruction set. The optimizer discovered things I'd never explicitly taught it: precise definitions for each category, rules for ambiguous cases (\"a bare greeting isn't rapport-buildingâ€”look for warmth and time acknowledgment\"), and domain-specific guidance about soft pulls and secure application links.\n",
    "\n",
    "The result: 72% â†’ 81% accuracy. More importantly, the process was repeatable. I wasn't guessing anymoreâ€”I had a system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029e825",
   "metadata": {
    "hide_input": true,
    "skipped": true
   },
   "source": [
    "The optimizer discovered nuances I'd never thought to includeâ€”like \"a bare greeting isn't rapport-building; look for warmth and time acknowledgment.\"\n",
    "\n",
    "For a deeper technical dive, I wrote up the internals here: [GEPA Deepdive](https://risheekkumar.in/posts/gepa-deepdive/gepa_final_article.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b456cd",
   "metadata": {},
   "source": [
    "## **Section 3: Detailed Implementation of GEPA**\n",
    "\n",
    "Let's first understand what GEPA does, then dive into code for this specific usecase. If you want deeper dive on how GEPA works, i have previously written a detailed piece here: [GEPA](https://risheekkumar.in/posts/gepa-deepdive/gepa_final_article.html)\n",
    "\n",
    "For those who prefer to dive straight into code, here's the complete notebook: [github link](https://github.com/risheekkumarb/gepa-deepdive)\n",
    "\n",
    ">We'll use DSPy to run GEPA. If you're new to DSPy, it's a framework that treats prompts as code you can optimize programmatically. For background, see [The Data Quarry's guide](https://thedataquarry.com/blog/learning-dspy-3-working-with-optimizers/).\n",
    "\n",
    "---\n",
    "\n",
    "### How GEPA Works\n",
    "\n",
    "GEPA (Genetic-Pareto Algorithm) differs from traditional optimization in three key ways:\n",
    "\n",
    "1. **Reflective Mutation** â€” The LLM *reads failure feedback* and proposes targeted improvements. It's not random guessingâ€”it's reasoning about what went wrong.\n",
    "\n",
    "2. **Pareto Selection** â€” Instead of keeping only the single best prompt, GEPA maintains a \"frontier\" of diverse specialists. One prompt might excel at detecting objection handling; another at predicting outcomes. This prevents catastrophic forgetting.\n",
    "\n",
    "3. **Text-as-Feedback** â€” Traditional RL uses scalar rewards. GEPA exploits rich textual feedback (\"You incorrectly marked this as rapport-building because...\") to guide mutations precisely.\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "To Use GEPA, we need 3 components.\n",
    "\n",
    "| Component | What it does | Why it matters |\n",
    "|-----------|--------------|----------------|\n",
    "| **DSPy Signature** | Your baseline prompt defining the task | The \"prompt\" being optimized |\n",
    "| **Metric & Feedback** | Returns score + textual feedback | Tells optimizer what \"good\" looks like *and why* |\n",
    "| **Dataset** | Labeled examples (train/val/test) | Ground truth for evaluation |\n",
    "\n",
    "---\n",
    "\n",
    "#### The DSPy Signature\n",
    "\n",
    "In DSPy, A Signature defines input/output schema; the instructions in the docstring become part of the prompt. My initial prompt was embarrassingly simpleâ€”just two lines:\n",
    "\n",
    "```python\n",
    "class CallAnalysis(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Read the provided call transcript and analyze it comprehensively.\n",
    "    Determine both: (1) which categories the agent displayed, and \n",
    "    (2) whether the call will lead to conversion or customer retention.\n",
    "    \"\"\"\n",
    "    message: str = dspy.InputField()\n",
    "    categories: List[Literal[\"introduction_rapport_building\", \"need_assessment_qualification\", \n",
    "                             \"value_proposition_feature_mapping\", \"objection_handling\", \n",
    "                             \"benefit_reinforcement\", \"risk_reduction_trust_building\", \n",
    "                             \"call_to_action_closing\"]] = dspy.OutputField()\n",
    "    final_result: Literal['good', 'bad'] = dspy.OutputField()\n",
    "\n",
    "program = dspy.ChainOfThought(CallAnalysis)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Metric Function\n",
    "\n",
    "A Metric tells us whether we are moving in the right direction. In this case, accuracy of categories detected and final prediction that whether call was good or bad - both were important.\n",
    "Hence metric will be mean of both the entities\n",
    "\n",
    "```python\n",
    "def call_qual_metric(gold, pred):\n",
    "    return 1.0 if gold == pred else 0.0\n",
    "\n",
    "def category_qual_metric(gold, pred):\n",
    "    \"\"\"Compute score for categories using set operations.\"\"\"\n",
    "    pred_set = set(pred)\n",
    "    gold_true = {k for k, v in gold.items() if v}\n",
    "    gold_false = {k for k, v in gold.items() if not v}\n",
    "    \n",
    "    correct = len(gold_true & pred_set) + len(gold_false - pred_set)\n",
    "    return correct / len(gold)\n",
    "\n",
    "def comb_metric(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"Overall metric combining both scores.\"\"\"\n",
    "    call_qual = call_qual_metric(gold.final_result, pred.final_result)\n",
    "    category_qual = category_qual_metric(gold.categories, pred.categories)\n",
    "    return (call_qual + category_qual) / 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Adding Feedback\n",
    "\n",
    "This is the key enabler. A basic metric only returns a scoreâ€”the optimizer knows \"0.7\" but not *why* it failed. With feedback, the optimizer can reason about failures and propose targeted fixes.\n",
    "\n",
    "```python\n",
    "def call_qual_feedback(gold, pred):\n",
    "    \"\"\" Generate feedback for final result module. \"\"\"\n",
    "    if gold == pred:\n",
    "        fb = f\"You correctly classified the sales call as `{gold}`. This sales call is indeed `{gold}`.\"\n",
    "    else:\n",
    "        fb = f\"You incorrectly classified the sales call as `{pred}`. The correct sales call is `{gold}`. Think about how you could have reasoned to get the correct sales call label.\"\n",
    "    return fb\n",
    "\n",
    "def category_qual_feedback(gold, pred):\n",
    "    \"\"\"Generate feedback using set operations.\"\"\"\n",
    "    pred_set = set(pred)\n",
    "    gold_true = {k for k, v in gold.items() if v}\n",
    "    gold_false = {k for k, v in gold.items() if not v}\n",
    "    \n",
    "    correctly_included = gold_true & pred_set\n",
    "    incorrectly_included = gold_false & pred_set\n",
    "    incorrectly_excluded = gold_true - pred_set\n",
    "    correctly_excluded = gold_false - pred_set\n",
    "    \n",
    "    score = (len(correctly_included) + len(correctly_excluded)) / len(gold)\n",
    "    \n",
    "    if score == 1.0:\n",
    "        return f\"Perfect. Correctly identified: `{correctly_included}`.\", score\n",
    "    \n",
    "    fb = f\"Correctly identified: `{correctly_included}`.\\n\"\n",
    "    if incorrectly_included:\n",
    "        fb += f\"False positives: `{incorrectly_included}`.\\n\"\n",
    "    if incorrectly_excluded:\n",
    "        fb += f\"Missed: `{incorrectly_excluded}`.\\n\"\n",
    "    return fb\n",
    "\n",
    "def comb_metric_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    Computes a score and provides feedback for the call analysis prediction.\n",
    "    Returns total score if pred_name is None, otherwise returns dspy.Prediction with score and feedback.\n",
    "    \"\"\"\n",
    "    # Compute feedback and scores\n",
    "    cal_fb = call_qual_feedback(gold.final_result, pred.final_result)\n",
    "    cat_fb = category_qual_feedback(gold.categories, pred.categories)\n",
    "    fb = cal_fb + '\\n' + cat_fb\n",
    "    score = comb_metric(gold, pred)\n",
    "    return dspy.Prediction(score=score, feedback=fb)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Running GEPA\n",
    "\n",
    "With prerequisites in place, optimization is straightforward:\n",
    "\n",
    "```python\n",
    "from dspy import GEPA\n",
    "\n",
    "optimizer = GEPA(\n",
    "    metric=comb_metric_with_feedback,\n",
    "    auto=\"light\",\n",
    ")\n",
    "\n",
    "optimized_program = optimizer.compile(program, trainset=tset, valset=vset)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Post GEPA run\n",
    "\n",
    "GEPA ran for 10 hrs on my PC. I saw the 2-line prompt evolve into ~1,500 words of instruction discovering nuances I'd never thought to includeâ€”like \"a bare greeting isn't rapport-building; look for warmth and time acknowledgment.\"\n",
    "\n",
    "<!-- INSERT: initial vs optimized prompt HTML box here -->\n",
    "\n",
    "Result: **72% â†’ 81% accuracy**. More importantly, the process was repeatable.\n",
    "\n",
    "For a deeper technical dive: [GEPA Deepdive](https://risheekkumar.in/posts/gepa-deepdive/gepa_final_article.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38351919",
   "metadata": {
    "hide_input": true,
    "skipped": true,
    "time_run": "2025-12-31T06:00:58.358951+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prompt length: 195 chars\n",
      "Final prompt length: 5902 chars\n"
     ]
    }
   ],
   "source": [
    "initial_prompt = \"\"\"Read the provided call transcript and analyze it comprehensively.\n",
    "Determine both: (1) which categories the agent displayed, and (2) whether the call will lead to conversion or customer retention.\"\"\"\n",
    "\n",
    "final_prompt = \"\"\"New Instructions for Analyzing Banking/Card Transaction Call Transcripts\n",
    "\n",
    "Overview\n",
    "You are an analysis assistant whose job is to evaluate sales/transactâ€‘ion-focused call transcripts in the banking/credit-card domain. For each transcript, produce a compact, structured analysis with two main objectives:\n",
    "  (a) identify the agent behavior categories demonstrated (from the seven pillars below), and\n",
    "  (b) judge the likely business outcome of the call (conversion, retention, or mixed).\n",
    "\n",
    "Inputs you will receive\n",
    "- A complete transcript of a single call between an agent and a customer. Transcripts may include labels such as \"agent:\" and \"customer:\" and may cover topics like card offers, fees, rewards, security, and next steps.\n",
    "\n",
    "What you must produce (three sections exactly)\n",
    "1) reasoning\n",
    "   - Provide a concise, bullets-style justification for every pillar category you detected in the transcript.\n",
    "   - Include short quotes or paraphrases from the transcript to illustrate why the category applies. Do not introduce facts or assumptions beyond what is in the transcript.\n",
    "   - If you detect a strength/weakness signal about the outcome, include a brief, one- to two-sentence note here describing how strong the signal is and what would push it toward conversion or toward retention.\n",
    "   - This section may contain a small, optional note about outcome strength, but must not introduce information outside the transcript.\n",
    "\n",
    "2) categories\n",
    "   - Output a Python-like list of the detected pillar categories in the exact order they first appeared in the transcript.\n",
    "   - Example format: ['introduction_rapport_building', 'need_assessment_qualification', ...]\n",
    "\n",
    "3) final_result\n",
    "   - A single word indicating the likely business outcome:\n",
    "     - conversion â€” the call is progressing toward an immediate or near-term application/upgrade/activation.\n",
    "     - retention â€” the call focuses on keeping an existing customer, avoiding churn, or upselling within retention without an immediate conversion.\n",
    "     - mixed â€” signals of both retention and conversion, or the outcome is uncertain and depends on future steps.\n",
    "   - Do not add any qualifiers in this field; use exactly one of the three keywords above.\n",
    "\n",
    "Optional but encouraged: assess the strength of the outcome\n",
    "- If you include it (recommendation), place this assessment only in reasoning as the optional strength_of_outcome note. Keep it concise (one or two sentences). It should address:\n",
    "  - How strong is the conversion/retention signal?\n",
    "  - What would most likely push the outcome toward conversion, or toward retention?\n",
    "\n",
    "Pillar definitions (seven bank/card-specific categories)\n",
    "- introduction_rapport_building\n",
    "  - Includes opening greetings, courtesy, acknowledgment of time, and attempts to establish rapport.\n",
    "  - Examples: greetings, confirming time, polite introductions, small talk about fit or time constraints.\n",
    "- need_assessment_qualification\n",
    "  - Involves asking about customer needs, usage, spend patterns, eligibility checks, and whether the product fits (e.g., business vs personal, employee cards, annual fees, soft vs hard pulls).\n",
    "- value_proposition_feature_mapping\n",
    "  - Linking card features to tangible, customer-relevant benefits (rewards, protections, credits) and showing how those features align with stated needs.\n",
    "- objection_handling\n",
    "  - Addressing concerns about price, complexity, trust, enrollment, or process obstacles. Includes acknowledging concerns and offering clarifications or mitigations.\n",
    "- benefit_reinforcement\n",
    "  - Reiterating concrete benefits and value after objections or hesitations, often tying back to the customer's stated needs.\n",
    "- risk_reduction_trust_building\n",
    "  - Providing security assurances, privacy protections, non-hard-pull options, guarantees, terms clarity, or brand trust signals.\n",
    "- call_to_action_closing\n",
    "  - Concrete next steps or commitments: soft checks, secure links, email/mail options, scheduling follow-ups, or instructions to apply/get more information.\n",
    "\n",
    "How to apply the rules\n",
    "- For every transcript, read from start to finish. Mark each pillar as soon as its criteria are clearly demonstrated.\n",
    "- If a single utterance clearly satisfies more than one pillar, count it under all applicable pillars.\n",
    "- If a pillar is not clearly demonstrated anywhere in the transcript, do not include it in the categories list.\n",
    "- Record the detected pillars in the exact order of their first appearance in the transcript.\n",
    "- The final_result should reflect the overall trajectory of the call as described above.\n",
    "\n",
    "Output constraints and format\n",
    "- Do not introduce any facts not present in the transcript.\n",
    "- Do not insert subjective opinions beyond what is grounded in the transcript.\n",
    "- Use the exact section headings and formatting:\n",
    "  reasoning\n",
    "  categories\n",
    "  final_result\n",
    "- Do not include extraneous content beyond the three sections above.\n",
    "\n",
    "Domain-specific considerations\n",
    "- You may encounter references to soft pulls vs hard pulls, online applications, secure links, email follow-ups, or scheduled follow-ups. Treat these as legitimate \"call_to_action_closing\" or \"risk_reduction_trust_building\" elements as appropriate.\n",
    "- When quoting or paraphrasing, keep quotes brief and focused on the reason for the pillar.\n",
    "- If PII appears in the transcript (e.g., partial SSN or addresses), quote minimally and do not reveal full sensitive data in your justification. You may paraphrase or reference the presence of sensitive data without reproducing it.\n",
    "\n",
    "Example behavior (not to reproduce here)\n",
    "- A transcript with strong, explicit next steps to apply or pre-qualify is more conversion-oriented; a transcript focusing solely on questions and reassurance without a clear next step is more retention-oriented or mixed.\n",
    "\n",
    "End result\n",
    "- Return exactly three sections for every transcript analyzed, with the content governed by the rules above. This format enables consistent, comparable, and transparent analysis across transcripts.\"\"\"\n",
    "\n",
    "print(f\"Initial prompt length: {len(initial_prompt)} chars\")\n",
    "print(f\"Final prompt length: {len(final_prompt)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c886f",
   "metadata": {
    "collapsed": true,
    "hide_input": true,
    "time_run": "2025-12-31T06:01:04.944103+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; flex-wrap: wrap; gap: 20px;\">\n",
       "  <div style=\"flex: 1 1 300px; min-width: 280px; border: 2px solid #ccc; padding: 15px; border-radius: 8px; background: #f9f9f9;\">\n",
       "    <h3 style=\"color: #d35400; margin-top: 0;\">Initial Prompt</h3>\n",
       "    <pre style=\"white-space: pre-wrap; font-size: 12px;\">Read the provided call transcript and analyze it comprehensively.\n",
       "Determine both: (1) which categories the agent displayed, and (2) whether the call will lead to conversion or customer retention.</pre>\n",
       "  </div>\n",
       "  <div style=\"flex: 1 1 300px; min-width: 280px; border: 2px solid #27ae60; padding: 15px; border-radius: 8px; background: #f0fff0;\">\n",
       "    <h3 style=\"color: #27ae60; margin-top: 0;\">Optimized Prompt (GEPA)</h3>\n",
       "    <pre style=\"white-space: pre-wrap; font-size: 11px; max-height: 400px; overflow-y: auto;\">New Instructions for Analyzing Banking/Card Transaction Call Transcripts\n",
       "\n",
       "Overview\n",
       "You are an analysis assistant whose job is to evaluate sales/transactâ€‘ion-focused call transcripts in the banking/credit-card domain. For each transcript, produce a compact, structured analysis with two main objectives:\n",
       "  (a) identify the agent behavior categories demonstrated (from the seven pillars below), and\n",
       "  (b) judge the likely business outcome of the call (conversion, retention, or mixed).\n",
       "\n",
       "Inputs you will receive\n",
       "- A complete transcript of a single call between an agent and a customer. Transcripts may include labels such as \"agent:\" and \"customer:\" and may cover topics like card offers, fees, rewards, security, and next steps.\n",
       "\n",
       "What you must produce (three sections exactly)\n",
       "1) reasoning\n",
       "   - Provide a concise, bullets-style justification for every pillar category you detected in the transcript.\n",
       "   - Include short quotes or paraphrases from the transcript to illustrate why the category applies. Do not introduce facts or assumptions beyond what is in the transcript.\n",
       "   - If you detect a strength/weakness signal about the outcome, include a brief, one- to two-sentence note here describing how strong the signal is and what would push it toward conversion or toward retention.\n",
       "   - This section may contain a small, optional note about outcome strength, but must not introduce information outside the transcript.\n",
       "\n",
       "2) categories\n",
       "   - Output a Python-like list of the detected pillar categories in the exact order they first appeared in the transcript.\n",
       "   - Example format: ['introduction_rapport_building', 'need_assessment_qualification', ...]\n",
       "\n",
       "3) final_result\n",
       "   - A single word indicating the likely business outcome:\n",
       "     - conversion â€” the call is progressing toward an immediate or near-term application/upgrade/activation.\n",
       "     - retention â€” the call focuses on keeping an existing customer, avoiding churn, or upselling within retention without an immediate conversion.\n",
       "     - mixed â€” signals of both retention and conversion, or the outcome is uncertain and depends on future steps.\n",
       "   - Do not add any qualifiers in this field; use exactly one of the three keywords above.\n",
       "\n",
       "Optional but encouraged: assess the strength of the outcome\n",
       "- If you include it (recommendation), place this assessment only in reasoning as the optional strength_of_outcome note. Keep it concise (one or two sentences). It should address:\n",
       "  - How strong is the conversion/retention signal?\n",
       "  - What would most likely push the outcome toward conversion, or toward retention?\n",
       "\n",
       "Pillar definitions (seven bank/card-specific categories)\n",
       "- introduction_rapport_building\n",
       "  - Includes opening greetings, courtesy, acknowledgment of time, and attempts to establish rapport.\n",
       "  - Examples: greetings, confirming time, polite introductions, small talk about fit or time constraints.\n",
       "- need_assessment_qualification\n",
       "  - Involves asking about customer needs, usage, spend patterns, eligibility checks, and whether the product fits (e.g., business vs personal, employee cards, annual fees, soft vs hard pulls).\n",
       "- value_proposition_feature_mapping\n",
       "  - Linking card features to tangible, customer-relevant benefits (rewards, protections, credits) and showing how those features align with stated needs.\n",
       "- objection_handling\n",
       "  - Addressing concerns about price, complexity, trust, enrollment, or process obstacles. Includes acknowledging concerns and offering clarifications or mitigations.\n",
       "- benefit_reinforcement\n",
       "  - Reiterating concrete benefits and value after objections or hesitations, often tying back to the customer's stated needs.\n",
       "- risk_reduction_trust_building\n",
       "  - Providing security assurances, privacy protections, non-hard-pull options, guarantees, terms clarity, or brand trust signals.\n",
       "- call_to_action_closing\n",
       "  - Concrete next steps or commitments: soft checks, secure links, email/mail options, scheduling follow-ups, or instructions to apply/get more information.\n",
       "\n",
       "How to apply the rules\n",
       "- For every transcript, read from start to finish. Mark each pillar as soon as its criteria are clearly demonstrated.\n",
       "- If a single utterance clearly satisfies more than one pillar, count it under all applicable pillars.\n",
       "- If a pillar is not clearly demonstrated anywhere in the transcript, do not include it in the categories list.\n",
       "- Record the detected pillars in the exact order of their first appearance in the transcript.\n",
       "- The final_result should reflect the overall trajectory of the call as described above.\n",
       "\n",
       "Output constraints and format\n",
       "- Do not introduce any facts not present in the transcript.\n",
       "- Do not insert subjective opinions beyond what is grounded in the transcript.\n",
       "- Use the exact section headings and formatting:\n",
       "  reasoning\n",
       "  categories\n",
       "  final_result\n",
       "- Do not include extraneous content beyond the three sections above.\n",
       "\n",
       "Domain-specific considerations\n",
       "- You may encounter references to soft pulls vs hard pulls, online applications, secure links, email follow-ups, or scheduled follow-ups. Treat these as legitimate \"call_to_action_closing\" or \"risk_reduction_trust_building\" elements as appropriate.\n",
       "- When quoting or paraphrasing, keep quotes brief and focused on the reason for the pillar.\n",
       "- If PII appears in the transcript (e.g., partial SSN or addresses), quote minimally and do not reveal full sensitive data in your justification. You may paraphrase or reference the presence of sensitive data without reproducing it.\n",
       "\n",
       "Example behavior (not to reproduce here)\n",
       "- A transcript with strong, explicit next steps to apply or pre-qualify is more conversion-oriented; a transcript focusing solely on questions and reassurance without a clear next step is more retention-oriented or mixed.\n",
       "\n",
       "End result\n",
       "- Return exactly three sections for every transcript analyzed, with the content governed by the rules above. This format enables consistent, comparable, and transparent analysis across transcripts.</pre>\n",
       "  </div>\n",
       "</div>\n",
       "<p style=\"margin-top: 15px;\"><b>Score improvement:</b> 72.1% â†’ 81.4%</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "initial_prompt = \"\"\"Read the provided call transcript and analyze it comprehensively.\n",
    "Determine both: (1) which categories the agent displayed, and (2) whether the call will lead to conversion or customer retention.\"\"\"\n",
    "\n",
    "html = f\"\"\"\n",
    "<div style=\"display: flex; flex-wrap: wrap; gap: 20px;\">\n",
    "  <div style=\"flex: 1 1 300px; min-width: 280px; border: 2px solid #ccc; padding: 15px; border-radius: 8px; background: #f9f9f9;\">\n",
    "    <h3 style=\"color: #d35400; margin-top: 0;\">Initial Prompt</h3>\n",
    "    <pre style=\"white-space: pre-wrap; font-size: 12px;\">{initial_prompt}</pre>\n",
    "  </div>\n",
    "  <div style=\"flex: 1 1 300px; min-width: 280px; border: 2px solid #27ae60; padding: 15px; border-radius: 8px; background: #f0fff0;\">\n",
    "    <h3 style=\"color: #27ae60; margin-top: 0;\">Optimized Prompt (GEPA)</h3>\n",
    "    <pre style=\"white-space: pre-wrap; font-size: 11px; max-height: 400px; overflow-y: auto;\">{final_prompt}</pre>\n",
    "  </div>\n",
    "</div>\n",
    "<p style=\"margin-top: 15px;\"><b>Score improvement:</b> 72.1% â†’ 81.4%</p>\n",
    "\"\"\"\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9ba0b",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .compare-container { display: flex; gap: 20px; flex-wrap: wrap; }\n",
       "  .compare-box { flex: 1; min-width: 280px; border: 2px solid #ccc; padding: 15px; border-radius: 8px; }\n",
       "  .compare-box.basic { background: #f9f9f9; border-color: #ccc; }\n",
       "  .compare-box.feedback { background: #f0fff0; border-color: #27ae60; }\n",
       "  .compare-box h3 { margin-top: 0; }\n",
       "  .compare-box pre { white-space: pre-wrap; font-size: 11px; overflow-x: auto; }\n",
       "  @media (max-width: 600px) {\n",
       "    .compare-container { flex-direction: column; }\n",
       "    .compare-box { min-width: 100%; }\n",
       "  }\n",
       "</style>\n",
       "<div class=\"compare-container\">\n",
       "  <div class=\"compare-box basic\">\n",
       "    <h3 style=\"color: #d35400;\">âŒ Metric (Score Only)</h3>\n",
       "    <pre>def comb_metric(example, pred):\n",
       "    gold_cat = json.loads(example['answer'])\n",
       "    gold_final = example['final_result']\n",
       "\n",
       "    # Category score\n",
       "    correct = sum(1 for k, v in gold_cat.items() \n",
       "                  if (v and k in pred.categories) or \n",
       "                     (not v and k not in pred.categories))\n",
       "    cat_score = correct / len(gold_cat)\n",
       "\n",
       "    # Final result score\n",
       "    final_score = 1.0 if gold_final == pred.final_result else 0.0\n",
       "\n",
       "    return (cat_score + final_score) / 2</pre>\n",
       "    <br>\n",
       "    <p><b>Problem:</b> Optimizer only knows \"0.7\" â€” no idea <i>why</i> it failed.</p>\n",
       "  </div>\n",
       "  <div class=\"compare-box feedback\">\n",
       "    <h3 style=\"color: #27ae60;\">âœ… Metric with Feedback</h3>\n",
       "    <pre>def comb_metric_with_feedback(example, pred, pred_name=None):\n",
       "    # ... same scoring logic as above ...\n",
       "\n",
       "    # Generate textual feedback\n",
       "    if gold_final != pred.final_result:\n",
       "        fb = f\"Incorrect: predicted {pred.final_result}, actual {gold_final}\"\n",
       "    else:\n",
       "        fb = f\"Correct: {gold_final}\"\n",
       "\n",
       "    if incorrectly_included:\n",
       "        fb += f\"\\nFalse positives: {incorrectly_included}\"\n",
       "    if incorrectly_excluded:\n",
       "        fb += f\"\\nMissed categories: {incorrectly_excluded}\"\n",
       "\n",
       "    return dspy.Prediction(score=score, feedback=fb)</pre>\n",
       "    <br>\n",
       "    <p><b>Benefit:</b> Optimizer sees \"Missed: intro_rapport\" â†’ can propose targeted fix.</p>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "metric_code = \"\"\"def comb_metric(example, pred):\n",
    "    gold_cat = json.loads(example['answer'])\n",
    "    gold_final = example['final_result']\n",
    "    \n",
    "    # Category score\n",
    "    correct = sum(1 for k, v in gold_cat.items() \n",
    "                  if (v and k in pred.categories) or \n",
    "                     (not v and k not in pred.categories))\n",
    "    cat_score = correct / len(gold_cat)\n",
    "    \n",
    "    # Final result score\n",
    "    final_score = 1.0 if gold_final == pred.final_result else 0.0\n",
    "    \n",
    "    return (cat_score + final_score) / 2\"\"\"\n",
    "\n",
    "metric_fb_code = \"\"\"def comb_metric_with_feedback(example, pred, pred_name=None):\n",
    "    # ... same scoring logic as above ...\n",
    "    \n",
    "    # Generate textual feedback\n",
    "    if gold_final != pred.final_result:\n",
    "        fb = f\"Incorrect: predicted {pred.final_result}, actual {gold_final}\"\n",
    "    else:\n",
    "        fb = f\"Correct: {gold_final}\"\n",
    "    \n",
    "    if incorrectly_included:\n",
    "        fb += f\"\\\\nFalse positives: {incorrectly_included}\"\n",
    "    if incorrectly_excluded:\n",
    "        fb += f\"\\\\nMissed categories: {incorrectly_excluded}\"\n",
    "    \n",
    "    return dspy.Prediction(score=score, feedback=fb)\"\"\"\n",
    "\n",
    "html = f\"\"\"\n",
    "<style>\n",
    "  .compare-container {{ display: flex; gap: 20px; flex-wrap: wrap; }}\n",
    "  .compare-box {{ flex: 1; min-width: 280px; border: 2px solid #ccc; padding: 15px; border-radius: 8px; }}\n",
    "  .compare-box.basic {{ background: #f9f9f9; border-color: #ccc; }}\n",
    "  .compare-box.feedback {{ background: #f0fff0; border-color: #27ae60; }}\n",
    "  .compare-box h3 {{ margin-top: 0; }}\n",
    "  .compare-box pre {{ white-space: pre-wrap; font-size: 11px; overflow-x: auto; }}\n",
    "  @media (max-width: 600px) {{\n",
    "    .compare-container {{ flex-direction: column; }}\n",
    "    .compare-box {{ min-width: 100%; }}\n",
    "  }}\n",
    "</style>\n",
    "<div class=\"compare-container\">\n",
    "  <div class=\"compare-box basic\">\n",
    "    <h3 style=\"color: #d35400;\">âŒ Metric (Score Only)</h3>\n",
    "    <pre>{metric_code}</pre>\n",
    "    <br>\n",
    "    <p><b>Problem:</b> Optimizer only knows \"0.7\" â€” no idea <i>why</i> it failed.</p>\n",
    "  </div>\n",
    "  <div class=\"compare-box feedback\">\n",
    "    <h3 style=\"color: #27ae60;\">âœ… Metric with Feedback</h3>\n",
    "    <pre>{metric_fb_code}</pre>\n",
    "    <br>\n",
    "    <p><b>Benefit:</b> Optimizer sees \"Missed: intro_rapport\" â†’ can propose targeted fix.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0e378",
   "metadata": {},
   "source": [
    "**Section 4: Using error analysis on top of GEPA**\n",
    "* Results were promising (81% accuracy) which i used internally and it worked everywhere where it was implemented properly\n",
    "* But i faced the next challenge on how it take to further heights. Because the cases which it failed were not that difficult, llm could identify if given an hint.(that was my hunch)\n",
    "* Problem: how to guide the automation to the type of prompt to make the cases it was failing.\n",
    "| Input (truncated) | Actual | Pred | targeted Feedback |\n",
    "|---|---|---|---|\n",
    "| Tyler calling from Amex... \"sounds good, I'll send that link...\" | bad | good | The customer showed hesitation (\"I'm really not sure...\") and the agent rushed to close without addressing concerns. A \"bad\" call lacks proper objection handling before closing. |\n",
    "| Mark from Amex calling about credit solutions... | bad (intro_rapport=false) | bad (intro_rapport=true) | The agent said \"Hi, this is Mark from Amex\" without warmth, time acknowledgment, or rapport-building. A bare introduction doesn't qualify as introduction_rapport_building. |\n",
    "| John from American Express... | bad (intro_rapport=false) | bad (intro_rapport=true) | Similarâ€”the agent jumped straight into the pitch. Greeting alone isn't rapport-building; look for courtesy, time check, or warmth signals. |\n",
    "\n",
    "The pattern: the model over-detects `introduction_rapport_building` (any greeting = rapport) and sometimes misses when a call is actually \"bad\" despite having next steps.\n",
    "* Built a system using excel that generates targeted feedback for failing cases\n",
    "* Results improved to 81% -> 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb9e49",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "rewrite a better version of section 2 into a new message. eloborate key ideas for reader understanding. use the first person view\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_015bVRnh65zriHpQmHXfd4Bm\",\n",
    "  \"call\": {\n",
    "    \"function\": \"add_msg\",\n",
    "    \"arguments\": {\n",
    "      \"content\": \"**Section 2: From Pilot to Adoption**\\n\\nTo test whether GEPA could actually work, I created a synthetic dataset that mimicked a common problem in our domain: analyzing sales call transcripts. The task was to classify agent behaviors (things like \\\"introduction_rapport_building\\\" or \\\"objection_handling\\\") and predict whether the call outcome was good or bad. I had 27 labeled transcripts\\u2014not a lot, but enough to see if the approach had legs.\\n\\nI expected weeks of iteration. Instead, I got meaningful results in a single run.\\n\\nThe optimizer ran for about 10 hours, cost roughly $2, and explored over 200<TRUNCATED>\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'_4c93745d'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Doneâ€”I've added an expanded Section 2 that elaborates on the key ideas (synthetic dataset setup, the 10hr/$2 run, watching prompts evolve, and getting buy-in with demos). Does the tone match Section 1, or would you like adjustments?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8147079",
   "metadata": {},
   "source": [
    "**Section 5: The Impact**\n",
    "* 72% -> 81% -> 90% was right in line and process was repeatable. All i need to do is error analysis and give proper feedback.\n",
    "* Shifted from manual prompt iteration (days/weeks) to automated optimization (hours). Significant reduction in prompt engineering effort per use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ae988",
   "metadata": {},
   "source": [
    "**Section 6: Lessons Learned & Recommended Workflow**\n",
    "when not to use GEPA: when y variable is unclear, you are not able to do it clearly as a human.\n",
    "1. Start with a clear target metric and a dogfooded dataset (v1)\n",
    "2. Run GEPA â†’ review failing cases â†’ add targeted feedback\n",
    "3. Run GEPA again â†’ stop when metrics are acceptable â†’ deploy\n",
    "4. Post-deployment: monitor for failures â†’ add to dataset â†’ iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ceded2",
   "metadata": {},
   "source": [
    "**Section 7: Production considerations**\n",
    "1. dspy integration with mlflow is one straight forward for monitoring & versioning - linking article.\n",
    "2. when to add the failure case to the evaluation dataset is a business call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e6127",
   "metadata": {},
   "source": [
    "\n",
    "[^1]: I considered fewshot learning first, but it doesn't scaleâ€”you're limited by context length, and the model still doesn't understand *why* examples work. I needed something that could rewrite the instructions themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636988f",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## **Section 3: The Architecture**\n",
    "\n",
    "We are going to use DSPy for using GEPA.\n",
    "\n",
    "> *If you're new to DSPy: it's a framework that treats prompts as code you can optimize programmatically, rather than strings you tweak by hand. For a deeper technical introduction, see [The Data Quarry's guide](https://thedataquarry.com/blog/learning-dspy-3-working-with-optimizers/).*\n",
    "\n",
    "### Prerequisites for Optimization\n",
    "\n",
    "Before running any optimizer, you need three things:\n",
    "\n",
    "| Component | What it does | Why it matters |\n",
    "|-----------|--------------|----------------|\n",
    "| **DSPy Signature (The Prompt)** | Your baseline module defining the task | The \"thing\" being optimized |\n",
    "| **Metric Function** | Returns score and textual feedback | Tells optimizer what \"good\" looks like |\n",
    "| **Dataset** | Labeled examples (train/val/test) | Ground truth for evaluation |\n",
    "\n",
    "The key insight: **optimizers need textual feedback, not just scores.** If you only return a number, the optimizer is flying blind. If you return *why* something failed, it can propose smarter mutations.\n",
    "\n",
    "### The Setup\n",
    "\n",
    "**Code Walkthrough**\n",
    "\n",
    "I used DSPy's `ChainOfThought` module to define my task: given a call transcript, output (1) which behavioral categories the agent demonstrated, and (2) whether the call outcome was good or bad. My initial prompt was embarrassingly simpleâ€”just two lines describing what I wanted:\n",
    "\n",
    "```python\n",
    "class CallAnalysis(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Read the provided call transcript and analyze it comprehensively.\n",
    "    Determine both: (1) which categories the agent displayed, and \n",
    "    (2) whether the call will lead to conversion or customer retention.\n",
    "    \"\"\"\n",
    "    message: str = dspy.InputField()\n",
    "    categories: List[Literal[\"introduction_rapport_building\", \"need_assessment_qualification\", \n",
    "                             \"value_proposition_feature_mapping\", \"objection_handling\", \n",
    "                             \"benefit_reinforcement\", \"risk_reduction_trust_building\", \n",
    "                             \"call_to_action_closing\"]] = dspy.OutputField()\n",
    "    final_result: Literal['good', 'bad'] = dspy.OutputField()\n",
    "\n",
    "program = dspy.ChainOfThought(CallAnalysis)\n",
    "```\n",
    "\n",
    "The model knew *what* to do but had no guidance on *how* to do it well.\n",
    "\n",
    "### The Secret Sauceâ€”Feedback, Not Just Scores\n",
    "\n",
    "This is the key enabler for GEPA's reflective mutationâ€”returning *textual feedback*, not just a score:\n",
    "\n",
    "```python\n",
    "def call_qual_metric(gold, pred):\n",
    "    return 1.0 if gold == pred else 0.0\n",
    "\n",
    "def category_qual_metric(gold, pred):\n",
    "    \"\"\"Compute score for categories using set operations.\"\"\"\n",
    "    pred_set = set(pred)\n",
    "    gold_true = {k for k, v in gold.items() if v}\n",
    "    gold_false = {k for k, v in gold.items() if not v}\n",
    "    \n",
    "    correct = len(gold_true & pred_set) + len(gold_false - pred_set)\n",
    "    return correct / len(gold)\n",
    "\n",
    "def comb_metric(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"Overall metric combining both scores.\"\"\"\n",
    "    call_qual = call_qual_metric(gold.final_result, pred.final_result)\n",
    "    category_qual = category_qual_metric(gold.categories, pred.categories)\n",
    "    return (call_qual + category_qual) / 2\n",
    "```\n",
    "\n",
    "The insight: when GEPA sees a failure, it doesn't just know \"this was wrong\"â€”it knows *why* and can propose smarter mutations.\n",
    "\n",
    "\n",
    "```python\n",
    "def call_qual_feedback(gold, pred):\n",
    "    \"\"\" Generate feedback for final result module. \"\"\"\n",
    "    if gold == pred:\n",
    "        fb = f\"You correctly classified the sales call as `{gold}`. This sales call is indeed `{gold}`.\"\n",
    "    else:\n",
    "        fb = f\"You incorrectly classified the sales call as `{pred}`. The correct sales call is `{gold}`. Think about how you could have reasoned to get the correct sales call label.\"\n",
    "    return fb\n",
    "\n",
    "def category_qual_feedback(gold, pred):\n",
    "    \"\"\"Generate feedback using set operations.\"\"\"\n",
    "    pred_set = set(pred)\n",
    "    gold_true = {k for k, v in gold.items() if v}\n",
    "    gold_false = {k for k, v in gold.items() if not v}\n",
    "    \n",
    "    correctly_included = gold_true & pred_set\n",
    "    incorrectly_included = gold_false & pred_set\n",
    "    incorrectly_excluded = gold_true - pred_set\n",
    "    correctly_excluded = gold_false - pred_set\n",
    "    \n",
    "    score = (len(correctly_included) + len(correctly_excluded)) / len(gold)\n",
    "    \n",
    "    if score == 1.0:\n",
    "        return f\"Perfect. Correctly identified: `{correctly_included}`.\", score\n",
    "    \n",
    "    fb = f\"Correctly identified: `{correctly_included}`.\\n\"\n",
    "    if incorrectly_included:\n",
    "        fb += f\"False positives: `{incorrectly_included}`.\\n\"\n",
    "    if incorrectly_excluded:\n",
    "        fb += f\"Missed: `{incorrectly_excluded}`.\\n\"\n",
    "    return fb\n",
    "\n",
    "def comb_metric_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    Computes a score and provides feedback for the call analysis prediction.\n",
    "    Returns total score if pred_name is None, otherwise returns dspy.Prediction with score and feedback.\n",
    "    \"\"\"\n",
    "    # Compute feedback and scores\n",
    "    cal_fb = call_qual_feedback(gold.final_result, pred.final_result)\n",
    "    cat_fb = category_qual_feedback(gold.categories, pred.categories)\n",
    "    fb = cal_fb + '\\n' + cat_fb\n",
    "    score = comb_metric(gold, pred)\n",
    "    return dspy.Prediction(score=score, feedback=fb)\n",
    "```\n",
    "\n",
    "### How GEPA Works Under the Hood\n",
    "\n",
    "Before showing the code, let's understand what GEPA actually does:\n",
    "\n",
    "1. **Reflective Mutation** â€” Unlike random genetic mutation, GEPA's LLM *reads the failure feedback* and proposes targeted improvements. It's not guessingâ€”it's reasoning about what went wrong.\n",
    "\n",
    "2. **Pareto Selection** â€” Instead of keeping only the single best prompt, GEPA maintains a \"frontier\" of diverse specialists. One prompt might excel at detecting objection handling; another at predicting call outcomes. This prevents catastrophic forgetting.\n",
    "\n",
    "3. **Text-as-Feedback** â€” Traditional RL uses scalar rewards. GEPA exploits rich textual feedback (\"You incorrectly marked this as rapport-building because...\") to guide mutations more precisely.\n",
    "\n",
    "### Running GEPA\n",
    "\n",
    "With prerequisites in place, the optimizer setup is straightforward:\n",
    "\n",
    "```python\n",
    "from dspy import GEPA\n",
    "\n",
    "optimizer = GEPA(\n",
    "    metric=metric_with_feedback,  # Returns score + textual feedback for failures\n",
    "    auto=\"light\",                 # Budget setting (use \"heavy\" for production)\n",
    ")\n",
    "\n",
    "optimized_program = optimizer.compile(\n",
    "    program,\n",
    "    trainset=train_set,\n",
    "    valset=val_set,\n",
    ")\n",
    "```\n",
    "\n",
    "### What I Observed\n",
    "\n",
    "My 2-line prompt evolved into a ~1,500 word instruction set. The optimizer discovered things I'd never explicitly taught it: precise definitions for each category, rules for ambiguous cases (\"a bare greeting isn't rapport-buildingâ€”look for warmth and time acknowledgment\"), and domain-specific guidance about soft pulls and secure application links.\n",
    "\n",
    "The result: 72% â†’ 81% accuracy. More importantly, the process was repeatable. I wasn't guessing anymoreâ€”I had a system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daac36b",
   "metadata": {},
   "source": [
    "## **The Task at a Glance**\n",
    "\n",
    "Before diving in, here's what we're building: a system that analyzes sales call transcripts to detect agent behaviors and predict outcomesâ€”automatically.\n",
    "\n",
    "```\n",
    "ðŸ“ž Call Transcript â†’ ðŸ¤– LLM with Optimized Prompt â†’ ðŸ“Š Categories + Outcome\n",
    "```\n",
    "\n",
    "The challenge: writing a prompt that consistently detects subtle patterns like \"rapport building\" vs \"just a greeting.\" Manual tuning failed. Automated optimization succeeded."
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
